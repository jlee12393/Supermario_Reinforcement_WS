{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  강화학습을 이용한 인공지능 슈퍼마리오 만들기 메뉴얼_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이 메뉴얼은 슈퍼마리오 환경 설치부터 강화학습 알고리즘(DQN)을 이용해 똑똑한 Super마리오를 만들기 위한 메뉴얼 입니다\n",
    "\n",
    "먼저 슈퍼마리오가 환경과 어떻게 상호작용을 하며 학습을 하는지, 그리고 학습을 하기위해 필요한 함수들은 어떠한 것들이 있는지 보겠습니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 먼저 슈퍼마리오 게임 설명을 하겠습니다, \n",
    "\n",
    "총 0레벨부터 31 레벨까지 있습니다 ^^\n",
    "\n",
    "그리고 각 레벨의 스코어는 각 레벨당 0~1000 의 범위 안에 있습니다. \n",
    "\n",
    "그래서 우리의 목표는 모든 레벨을 클리어하는 것이므로 32000점을 받는것이 목표입니다!\n",
    "\n",
    "다음 레벨로 넘어가려면 레벨스코어에서 최소한 600점 이상을 받아야 합니다. \n",
    "\n",
    "\n",
    "#### 환경을 초기하려면 \n",
    "\n",
    "import gym\n",
    "\n",
    "env=gym.make('ppaquette/meta-SuperMarioBros-v0')\n",
    "\n",
    "\n",
    "env.reset() \n",
    "\n",
    "하시면 env.reset()을 통하여 emulator인 fceux가 실행됩니다. \n",
    "\n",
    "\n",
    "마리오가 죽으면 게임이 종료되고 게임을 시작하면 일정시간 내에 목표지점인 깃발까지 도착해야 합니다.\n",
    "\n",
    "\n",
    "총 reward는 목표까지의 X측의 거리 입니다 ^^ (깃발까지 가깝게 가면 갈수록 더 많은 reward를 받습니다 ^^) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "레벨을 넘어가게 만드는 방법으로는 두가지 방법이 있습니다. \n",
    "\n",
    "하나는 직접 바꿔주는 방법입니다. \n",
    "\n",
    "\n",
    "마리오가 action을 선택했을때 env.step() 함수를 통하여 마리오가 action을 선택하면 \n",
    "\n",
    "env.step(action)\n",
    "\n",
    "\n",
    "obs, reward, is_finished, info 의 값을 받습니다. \n",
    "\n",
    "첫번째는 그 선택을 해서 받은 observation입니다. \n",
    "\n",
    "reward는 reward 값이고 is_finished 는 그 마리오가 죽었는지 아닌지에 대한 정보입니다. \n",
    "\n",
    "info는 딕셔너리 인데요. \n",
    "\n",
    "info에서는, \n",
    "\n",
    "distance : 마리오가 X-axis로 이동한 거리 \n",
    "\n",
    "life : 총 3개의 목숨중에서 마리오가 몇개의 목숨을 가지고 있나 입니다.\n",
    "\n",
    "score : 현재 스코어 입니다. \n",
    "\n",
    "coins : 현재 가지고 있는 코인의 갯수 입니다. \n",
    "\n",
    "time : 현재 남은 시간의 정보 입니다. \n",
    "\n",
    "player_status : 작은마리오일때 -> 0 , 큰 마리오일때 ->1, 불꽃을 쏘는 마리오일때 ->2 의 값을 가지고있습니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. 슈퍼마리오 환경 불러오기\n",
    "\n",
    "*import gym*\n",
    "\n",
    "*import ppaquette_gym_super_mario*\n",
    "\n",
    "슈퍼마리오 환경을 임포트 합니다.\n",
    "\n",
    "*env = gym.make('ppaquette/meta-SuperMarioBros-v0')*\n",
    "\n",
    "gym의 함수인 make 함수를 사용하여 위에서 불러온 환경을 현재 환경으로 지정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gym\n",
    "import ppaquette_gym_super_mario\n",
    "env = gym.make('ppaquette/meta-SuperMarioBros-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ppaquette의 슈퍼마리오는 \n",
    "\n",
    "총 64개 버전의 마리오 환경을 제공하며 우리는 'ppaquette/meta-SuperMarioBros-v0'환경으로 학습을 하도록 하겠습니다. \n",
    "\n",
    "다른 버전의 환경을 이용하고 싶으시면 아래의 64개의 환경중 원하는 환경을 쓰시면 됩니다 ^^\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ppaquette/meta-SuperMarioBros-v0\n",
    "    ppaquette/meta-SuperMarioBros-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-1-1-v0\n",
    "    ppaquette/SuperMarioBros-1-2-v0\n",
    "    ppaquette/SuperMarioBros-1-3-v0\n",
    "    ppaquette/SuperMarioBros-1-4-v0\n",
    "    ppaquette/SuperMarioBros-2-1-v0\n",
    "    ppaquette/SuperMarioBros-2-2-v0\n",
    "    ppaquette/SuperMarioBros-2-3-v0\n",
    "    ppaquette/SuperMarioBros-2-4-v0\n",
    "    ppaquette/SuperMarioBros-3-1-v0\n",
    "    ppaquette/SuperMarioBros-3-2-v0\n",
    "    ppaquette/SuperMarioBros-3-3-v0\n",
    "    ppaquette/SuperMarioBros-3-4-v0\n",
    "    ppaquette/SuperMarioBros-4-1-v0\n",
    "    ppaquette/SuperMarioBros-4-2-v0\n",
    "    ppaquette/SuperMarioBros-4-3-v0\n",
    "    ppaquette/SuperMarioBros-4-4-v0\n",
    "    ppaquette/SuperMarioBros-5-1-v0\n",
    "    ppaquette/SuperMarioBros-5-2-v0\n",
    "    ppaquette/SuperMarioBros-5-3-v0\n",
    "    ppaquette/SuperMarioBros-5-4-v0\n",
    "    ppaquette/SuperMarioBros-6-1-v0\n",
    "    ppaquette/SuperMarioBros-6-2-v0\n",
    "    ppaquette/SuperMarioBros-6-3-v0\n",
    "    ppaquette/SuperMarioBros-6-4-v0\n",
    "    ppaquette/SuperMarioBros-7-1-v0\n",
    "    ppaquette/SuperMarioBros-7-2-v0\n",
    "    ppaquette/SuperMarioBros-7-3-v0\n",
    "    ppaquette/SuperMarioBros-7-4-v0\n",
    "    ppaquette/SuperMarioBros-8-1-v0\n",
    "    ppaquette/SuperMarioBros-8-2-v0\n",
    "    ppaquette/SuperMarioBros-8-3-v0\n",
    "    ppaquette/SuperMarioBros-8-4-v0\n",
    "    ppaquette/SuperMarioBros-1-1-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-1-2-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-1-3-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-1-4-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-2-1-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-2-2-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-2-3-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-2-4-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-3-1-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-3-2-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-3-3-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-3-4-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-4-1-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-4-2-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-4-3-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-4-4-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-5-1-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-5-2-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-5-3-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-5-4-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-6-1-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-6-2-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-6-3-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-6-4-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-7-1-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-7-2-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-7-3-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-7-4-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-8-1-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-8-2-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-8-3-Tiles-v0\n",
    "    ppaquette/SuperMarioBros-8-4-Tiles-v0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.화면 출력하기 \n",
    "env  의  reset 함수를 이용하여 슈퍼마리오의 초기화 상태를 화면으로 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ..., \n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에뮬레이터인 fceux를 통해 가만히 서 있는 마리오가 보인다면 성공입니다!\n",
    "\n",
    "현재 에이전트인 마리오는 action을 하고 있지 않아 Environment와 상호작용을 할수 없습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "\n",
    "임의의 action을 선택하는 mario 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_score = 0\n",
    "while total_score < 10: \n",
    "                action = env.action_space.sample()\n",
    "                obs, reward, is_finished, info = env.step(action)\n",
    "               \n",
    "                total_score = info[\"total_reward\"] #이런식으로 info 딕셔너리에서 reward를 가져옵니다.\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wrapper 사용하여 action과 inpute 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 슈퍼마리오 환경의 action은  MultiDiscrete 6 의 형태로 이루어 져있고, \n",
    "\n",
    "input size 는 224,256,3 입니다. \n",
    "\n",
    "이는 아래와 같이 env.action_space와  env.observation_space 함수를 통해 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiscrete6\n",
      "Box(224, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Wrapper  사용해서 action 형태 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 환경에서 슈퍼마리오는 [0,0,0,0,0,0] 과 같은 일차원 array로 action을 선택합니다. 예를 들면 [0,0,0,1,0,0] 의 배열을 action으로 받으면 슈퍼마리오는 오른쪽으로 움직입니다. \n",
    "현재 2차원 이상의 배열로 이루어져 있는 action을 1차원의 배열로 줄여주는 작업이 필요하고, 이는 wrapper  함수를 통하여 바꿀수 있습니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper import action_space # wrapper을 불러옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wra_act=action_space \n",
    "\n",
    "#reduce actions\n",
    "env=wra_act.mario_action(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시한번 env.action_space 함수를 통해 확인해보면 Discre14로 바뀐것을 볼 수 있습니다 ^^\n",
    "\n",
    "Discrete14 의 의미는 마리오가 환경에서 할 수 있는 action(가만히 있는다, 위, 아래, 왼쪽, 오른쪽, 점프, 불꽃쏘기) 버튼 조합을 14가지로 나타낸 것 입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Wrapper  사용해서 input size  줄이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강화학습을 학습하기 어려운 이유중 하나는 학습시간이 오래 걸리는 것인데요. \n",
    "이를 방지(?) 하기 위해 마찬가지로 wrapper을 통해 인풋 사이즈를 줄여주는 작업을 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce pixel\n",
    "\n",
    "\n",
    "env=wra_act.ProcessFrame84(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation_space 함수를 통해 다시 확인해보면, (84,84,1)로 인푸싸이즈가 줄여져 있는것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(84, 84, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 4장의 화면을 붙여 마리오게 적과 함정 정보주기\n",
    "\n",
    "슈퍼마리오는 화면을 보고 적의 위치와 함정등의 정보를 받아옵니다. \n",
    "\n",
    "만약 슈퍼마리오에게 화면이 멈춰진 한장면만 주어진다면, 적이 오는 것을 판단하기가 힘들것 입니다. \n",
    "\n",
    "그래서 멈춰진 화면 4개를 연속적으로 주어 마리오에게 적의 위치와 움직이는 방향을 판단할수 있게 해줘야합니다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ..., \n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ..., \n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ..., \n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " ..., \n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ..., \n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ..., \n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ..., \n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "\n",
    "obs=env.reset()\n",
    "print(obs)\n",
    "reshape_obs=np.reshape([obs],(1,84,84,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.stack((obs,obs,obs,obs), axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Reshape the history\n",
    "\n",
    "위에 만들어준 히스토리의 shape를 (1,84,84,4)로 바꿔줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.reshape([history], (1, 84, 84, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 append "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.append(reshape_obs, history[:,:,:,:3], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.shape(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Reshape again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_obs=np.reshape([history],(84,84,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 마리오가 E-epsilon 행동을 하게 만들기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "greedy 한  action 을 선택하게 해주는 함수를 만들어 줍니다. \n",
    "\n",
    "numpy의  np.random.rand()함수를 통해 epsilon 값보다 적은 값이 나올땐 0 부터 5까지의 임의의 값을 리턴해주고, \n",
    "\n",
    "epsilone 보다 큰 값이 나왔을때는 keras.predict  q value 의 값을 가장 크게 만드는 action을 리턴하게 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making an greedy action\n",
    "epsilon=0.9\n",
    "action_size=6\n",
    "\n",
    "import random\n",
    "\n",
    "def get_action(history):\n",
    "        history = np.float32(history / 255.0)\n",
    "        if np.random.rand() <= epsilon:\n",
    "            return random.randrange(action_size)\n",
    "        else:\n",
    "            q_value = model.predict(history)\n",
    "            return np.argmax(q_value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "action=get_action(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  강화학습을 이용한 인공지능 슈퍼마리오 만들기 메뉴얼 - 2\n",
    "\n",
    "이번에는 agent인 마리오가 action을 어떻게 선택하는지 보도록 하겠습니다. \n",
    "\n",
    "### 이 다음 cell부터는 \n",
    "1. Stop버튼을 누르시고\n",
    "2. fceux 에뮬레이터를 종료하신 뒤에\n",
    "3. Kernel에서 restart를 누르신 후 다시 실행해 주세요.\n",
    "\n",
    "\n",
    "\n",
    "##### 마리오는 다음과 같은 배열로 action을 인식합니다.\n",
    "\n",
    "Up, Left, Down, Right, A, B\n",
    "\n",
    "아무 action도 선택하지 않는 상태 : [0,0,0,0,0,0]\n",
    "\n",
    "위로가는(방향키 위)버튼을 선택한다  : [1,0,0,0,0,0]\n",
    "\n",
    "왼쪽으로 가는 action을 선택한다. : [0,1,0,0,0,0]\n",
    "\n",
    "아래로 가는 action을 선택한다. : [0,0,1,0,0,0]\n",
    "\n",
    "오른쪽으로 가는 action을 선택한다 : [0,0,0,1,0,0]\n",
    "\n",
    "점프를 하는 action을 선택한다(A버튼) : [0,0,0,0,1,0]\n",
    "\n",
    "버튼을 눌러 불꽃을 쏘는 action을 선택한다(B버튼): [0,0,0,0,0,1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "action = [0, 0, 0, 1, 1, 0]    # [up, left, down, right, A, B]\n",
    "\n",
    "이렇게 두개 버튼을 같이 선택한다면 4번째( 오른쪽 ) 와 5번째( 점프 )의 action을 같이 할것입니다.\n",
    "\n",
    "이와같이 6가지 action을 선택하며 환경을 통해 reward를 받습니다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gym\n",
    "import ppaquette_gym_super_mario\n",
    "\n",
    "import numpy as np\n",
    "from wrapper import action_space\n",
    "\n",
    "\n",
    "env = gym.make('ppaquette/meta-SuperMarioBros-v0')\n",
    "\n",
    "wra_act=action_space\n",
    "\n",
    "#reduce actions\n",
    "env=wra_act.mario_action(env)\n",
    "\n",
    "#reduce pixel\n",
    "\n",
    "\n",
    "env=wra_act.ProcessFrame84(env)\n",
    "\n",
    "\n",
    "#environment reset\n",
    "\n",
    "env.reset()\n",
    "\n",
    "\n",
    "\n",
    "action1=[0,0,0,0,0,0]\n",
    "action2=[1,0,0,0,0,0]\n",
    "action3=[0,1,0,0,0,0]\n",
    "action4=[0,0,1,0,0,0]\n",
    "action5=[0,0,0,1,0,0]\n",
    "action6=[0,0,0,0,1,0]\n",
    "action7=[0,0,0,0,0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### action을 선택하지 않은 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(30):\n",
    "    env.step(action1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위로가는(방향키 위)버튼을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    env.step(action2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왼쪽으로 가는 action선택 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    env.step(action3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래로 가는 action선택 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    env.step(action4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오른쪽으로 가는 action선택 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    env.step(action5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점프하는  action선택 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    env.step(action6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B 버튼 action선택  (불꽃!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    env.step(action7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위와같이 마리오는 6개의 action 중 목표까지 reward를 가장 많이 받을수 있는 action을 각 state에서 선택합니다.\n",
    "\n",
    "\n",
    "#### 슈퍼마리오메뉴얼 실습 1편에서는,\n",
    "\n",
    "    1. 슈퍼마리오의 환경이 action과 input size를 wrapper 하는 방법\n",
    "    2. Agent인 마리오가 action을 선택하는 방법\n",
    "    에 대하여 알아보았습니다. \n",
    "\n",
    "슈퍼마리오메뉴얼 실습 2편에서는 deep Q-network (DQN)을 이용하여 슈퍼마리오를 학습시켜보겠습니다. \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
